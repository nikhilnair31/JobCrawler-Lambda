![spook.png](https://pbxt.replicate.delivery/BQAmE4HRsQL0EBOiUQbnbynfwDiSzoMv4TNHYG7e002wVkqRA/discoart-result.png)

# JobCrawler-Lambda
JobCrawler is a powerful job scraping and curation platform powered by Metaphor API and OpenAI, deployed on AWS Lambda. It scours across teh interet to curate a list of job postings based on the technologies and projects individuals are working on based on your GitHub profile. Here's a glimpse into how JobCrawler can turbocharge your job search or talent acquisition strategy.

## Features:
- **Automated Job Scouring**: Harnessing the power of Metaphor API to perform deep searches to identify relevant job postings.
- **Intelligent Curation**: Utilizing OpenAI to analyze and categorize job postings, ensuring they are relevant to the skills and technologies found on GitHub profiles.
- **Scalable Architecture**: Deployed on AWS Lambda ensuring high availability and scalability.
- **GitHub Profile Analysis**: Beautiful Soup enables precise scraping of GitHub profiles to understand the technologies and projects individuals are engaged with.

## Getting Started:
### Prerequisites:
- AWS Account
- Metaphor API Key
- OpenAI API Key
- Python 3.11

### Installation:
- Clone the repository `git clone https://github.com/your-username/JobCrawler.git`
- `cd JobCrawler`
- Install the required packages `pip install -r requirements.txt`
- Configure your AWS

### Output:
The script will output a JSON file with the curated list of job postings based on the analysis of GitHub profiles.

## Contributing:
We welcome contributions! Please see the CONTRIBUTING.md file for details on how to contribute to JobCrawler.

## License:
JobCrawler is licensed under the MIT License - see the LICENSE.md file for details.